We first selected the top k movies which maximally activated each feature.  We then aimed to find tags prevalent in these movies in order to help us come up with meaningful class descriptions.  Popular and high quality tend to have more tags.  As such, in our latent space they tend to have higher than average values across all features.

To analyze which tags were most related to each feature, we used a weighted tag prevalence score based on the top normalized and averaged tags in the top k.  We also penalized this metric against high variance tags.
\begin{equation}
\label{eq:tagprev}
TagPrevalence = w1*normAvg + w2*Avg - w3*var
\end{equation}

Increasing w1 puts more emphasis on normalized tag values.  This pulls out tags which appear more prevalent in this class relative to other classes.  Tags like ``poverty'' and ``star wars'' will tend to appear for some classes which contain some related movies.

Increasing w2 puts more emphasis on raw tag values.  Tags which are popular within the class but not necessarily more popular than the entire population begin to appear.  Examples: ``original''and ``oscar'' tend to appear.

Increasing w3 penalize tags with large variance within the class.  For example if 1/3 of the movies in the class are related to poverty, then the ``poverty'' tag on these movies will tend to be high, but close to zero for the rest of the class.  With the normalized average, the class will appear highly related to poverty.  However by penalizing  tags with high variance, we can put weight against tags which are highly prevalent on only a subset of the top k, as we want tags related to all of the movies.

After manually tuning and examining the tags which were produced, we settled on k=200, w1=3, w2=6, and w3=2.  From manually looking at the top 20 movies, and prevalent tags for the top k movies, we came up with concise, human understandable class descriptions for each class.  The chosen tags are displayed on our web interface.